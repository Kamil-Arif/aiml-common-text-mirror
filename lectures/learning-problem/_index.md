---
title: The Learning Problem 
weight: 30
---

# The Learning Problem

## Chapter Flow

The flow of topics that we cover:

{{< mermaid align="left" theme="dark" >}}
graph TB;
    A(Basic Probability Concepts) --> C(Supervised Learning)
    C --> D(Other forms of learning)
    click A "../ml-math/probability"
{{< /mermaid >}}

After reading this chapter you should feel familiar with the following ideas and concepts:

1. What are the statistical distributions behind supervised learning. 
2. What is the hypothesis and hypothesis set. 
3. What is a supervised learning algorithm tries to do.
4. What are the other forms of learning from data.  

## The Supervised Learning Problem Statement

Let us start with a classic formal definition of the supervised learning problem.

![learning-problem](images/learning-problem.png#center)

*[Vapnik's](https://en.wikipedia.org/wiki/Vladimir_Vapnik) formulation of the learning problem (enhanced with notation from the Deep Learning book)*

The description below is taken from Vadimir Vapnik's classic book [Statistical Learing Theory](https://www.amazon.com/Statistical-Learning-Theory-Vladimir-Vapnik/dp/0471030031), albeit with some enhancements on terminology to make it more in line with our needs. 

The generator is a source of situations that determines the environment in which the target function (he calls it supervisor) and the learning algorithm act.  Here we consider the simplest environment: the data generator generates the vectors $\mathbf{x} \in \mathcal{X}$ independently and identically distributed (i.i.d.) according to some unknown (but fixed) probability distribution function $p(\mathbf{x})$.

The vector $\mathbf x$ are inputs to the target function (or operator); the target function returns the output values $y \in \mathcal{Y}$. The target function which transforms the vectors $\mathbf{x}$ into values $y$,  is **unknown** but we know that it exists and does not change. The target function effectively returns the output $y$ on the vector $\mathbf x$ according to  a conditional distribution function $p(y | \mathbf x)$.  

The learning _algorithm_ observes data that is drawn randomly and independently from the joint distribution function $p_{data}(\mathbf x , y) = p_{data}(\mathbf{x}) p_{data}(y | \mathbf x)$. The sampling distribution denoted as $\hat{p}_{data}$ produces _examples_ of inputs $\mathbf{x}$ and the targets (labels) $y$.

$$\mathtt{data} = \\{ (\mathbf{x}_1, y_1), \dots, (\mathbf{x}_m, y_m) \\}$$

 During what is called _training_, the learning algorithm constructs some operator which will he used for prediction of the supervisor's answer $y_i$ on any specific vector $\mathbf{x}_i$  generated by the generator. The goal of the learning algorithm is  to construct an **approximation** to the target function $f$. **Recall that we do not know this function but we do know that it exists.** We will symbolize this approximation $g$ and we will call it a _hypothesis_ drawn from a hypothesis set. The hypothesis is parametrized with a set of weights, the vector $\mathbf w$ and can be iteratively constructed so the final hypothesis, that results from the best possible $\mathbf w$, $\mathbf w^*$, is the one that is used to produce the predicted label $\hat{y}$. 
 
 The ability to optimally *predict*, according to a criterion, when observing data that we have _never seen before_, the _test set_, is called **generalization**. In summary, to learn we need three components:

 1. Data that may be stored or streaming in.
 2. Algorithms
 3. Objective function (Cost)

### Bayes Theorem

The Bayesian theorem is the cornerstone of probabilistic modeling and ultimately governs what models we can construct inside the _learning algorithm_ of the previous section. If $\mathbf{w}$ denotes the unknown parameters, $\mathtt{data}$ denotes the dataset and $\mathcal{H}$ denotes the hypothesis set.

$$ p(\mathbf{w} | \mathtt{data}, \mathcal{H}) =  \frac{P(  \mathtt{data} | \mathbf{w}, \mathcal{H}) P(\mathbf{w} | \mathcal{H}) }{ P(  \mathtt{data} | \mathcal{H})} $$

The Bayesian framework allows the introduction of _priors_ from a wide variety of sources (experts, other data, past posteriors, etc.) For example,a medical patient is exhibiting symptoms x, y and z. There are a number of diseases that could be causing all of them, but only a single disease is present. A doctor (the expert) has beliefs about which disease, but a second doctor may have slightly different beliefs.


A couple of examples of supervised learning are shown below:

![usps](images/usps.png)
*Examples from the MNIST training dataset used for classification*

![home-prices-area](images/home-prices-area.png)
*Birdseye view of home prices - Zillow predicts prices for similar homes in the same market. This is a regression problem.*


## Unsupervised Learning 

In unsupervised learning, we present a training set $\{ \mathbf{x}_1, \dots, \mathbf{x}_m \}$  without labels. The most common unsupervised learning method is clustering. We construct a partition of the data into a number of $K$ **clusters**, such that a suitably chosen loss function is minimized for a *different* set of input data (test).

![unsupervised](images/unsupervised.png)
*Clustering showing two classes and the exemplars per class*

## Semi-supervised Learning and Active Learning 

Semi-supervised learning stands between the supervised and unsupervised methods. One of the hottest methods in this category is the so called [Active learning](https://towardsdatascience.com/active-learning-tutorial-57c3398e34d). In many practical settings we simply cannot afford to label /annotate all $\mathbf x$ for very large $m$, and we need to select the ones that greedily result into the biggest performance metric gain (e.g. accuracy). 

## Reinforcement Learning

In reinforcement learning, a teacher is not providing a label (as in supervised learning) but rather a reward that judges whether the agent's action results on favorable environment states. In reinforcement learning we can learn end-to-end mappings from perceptions to actions. 
