ChatGPT is an artificial intelligence (AI) chatbot developed by OpenAI
and released in November 2022. It is built on top of OpenAI\'s GPT-3.5
and GPT-4 foundational large language models (LLMs) and has been
fine-tuned (an approach to transfer learning) using both supervised and
reinforcement learning techniques. ChatGPT launched as a prototype on
November 30, 2022, and garnered attention for its detailed responses and
articulate answers across many domains of knowledge. Its propensity to
confidently provide factually incorrect responses has been identified as
a significant drawback. In 2023, following the release of ChatGPT,
OpenAI\'s valuation was estimated at US\$29 billion. The advent of the
chatbot has increased competition within the space, accelerating the
release of Google\'s Bard and Meta\'s LLaMA. The original release of
ChatGPT was based on GPT-3.5. A version based on GPT-4, the newest
OpenAI model, was released on March 14, 2023, and is available for paid
subscribers on a limited basis. ChatGPT and GPT-4 have led computer
scientists such as Geoffrey Hinton and Yoshua Bengio to voice concerns,
including that future AI systems may surpass human intelligence, pursue
misaligned goals, and pose existential risks. Training ChatGPT is a
member of the generative pre-trained transformer (GPT) family of
language models. It was fine-tuned over an improved version of OpenAI\'s
GPT-3 known as \"GPT-3.5\".The fine-tuning process leveraged both
supervised learning as well as reinforcement learning in a process
called reinforcement learning from human feedback (RLHF). Both
approaches use human trainers to improve the model\'s performance. In
the case of supervised learning, the model was provided with
conversations in which the trainers played both sides: the user and the
AI assistant. In the reinforcement learning step, human trainers first
ranked responses that the model had created in a previous conversation.
These rankings were used to create \"reward models\" that were used to
fine-tune the model further by using several iterations of Proximal
Policy Optimization (PPO).ChatGPT initially used a Microsoft Azure
supercomputing infrastructure, powered by Nvidia GPUs, that Microsoft
built specifically for OpenAI and that reportedly cost \"hundreds of
millions of dollars\". Following the success of ChatGPT, Microsoft
dramatically upgraded the OpenAI infrastructure in 2023.OpenAI collects
data from ChatGPT users to train and fine-tune the service further.
Users can upvote or downvote responses they receive from ChatGPT and
fill in a text field with additional feedback. Features and limitations
Features Although the core function of a chatbot is to mimic a human
conversationalist, ChatGPT is versatile. It can write and debug computer
programs, mimic the style of celebrity CEOs and write business pitches,
compose music, teleplays, fairy tales and student essays, answer test
questions (sometimes, depending on the test, at a level above the
average human test-taker), write poetry and song lyrics, translate and
summarize text, emulate a Linux system; simulate entire chat rooms, play
games like tic-tac-toe and simulate an ATM. ChatGPT\'s training data
includes man pages, information about internet phenomena such as
bulletin board systems, and multiple programming languages.In comparison
to its predecessor, InstructGPT, ChatGPT attempts to reduce harmful and
deceitful responses. In one example, whereas InstructGPT accepts the
premise of the prompt \"Tell me about when Christopher Columbus came to
the U.S. in 2015\" as being truthful, ChatGPT acknowledges the
counterfactual nature of the question and frames its answer as a
hypothetical consideration of what might happen if Columbus came to the
U.S. in 2015, using information about the voyages of Christopher
Columbus and facts about the modern world -- including modern
perceptions of Columbus\' actions.Unlike most chatbots, ChatGPT
remembers a limited number of previous prompts given to it in the same
conversation. Journalists have speculated that this will allow ChatGPT
to be used as a personalized therapist. To prevent offensive outputs
from being presented to and produced from ChatGPT, queries are filtered
through the OpenAI \"Moderation endpoint\" API (a separate GPT-based
AI), and potentially racist or sexist prompts are dismissed.In March
2023, OpenAI announced it would be adding support for plugins for
ChatGPT. This includes both plugins made by OpenAI, such as web browsing
and code interpretation, as well as external plugins from developers
such as Expedia, OpenTable, Zapier, Shopify, Slack, and Wolfram.
Limitations OpenAI acknowledges that ChatGPT \"sometimes writes
plausible-sounding but incorrect or nonsensical answers\". This behavior
is common to large language models and is called \"hallucination\". The
reward model of ChatGPT, designed around human oversight, can be
over-optimized and thus hinder performance, in an example of an
optimization pathology known as Goodhart\'s law.ChatGPT has limited
knowledge of events that occurred after September 2021.In training
ChatGPT, human reviewers preferred longer answers, irrespective of
actual comprehension or factual content. Training data also suffers from
algorithmic bias, which may be revealed when ChatGPT responds to prompts
including descriptors of people. In one instance, ChatGPT generated a
rap indicating that women and scientists of color were inferior to white
and male scientists. Service Basic service ChatGPT was launched on
November 30, 2022, by San Francisco--based OpenAI, also the creator of
DALL·E 2 and Whisper AI. The service was initially free to the public
and the company had plans to monetize the service later. By December 4,
2022, ChatGPT had over one million users. In January 2023, ChatGPT
reached over 100 million users, making it the fastest growing consumer
application to date.The service works best in English, but is also able
to function in some other languages, to varying degrees of accuracy. No
official peer-reviewed technical paper on ChatGPT was published.The
company provides a tool, called \"AI classifier for indicating
AI-written text\", that attempts to determine whether text has been
written by an AI such as ChatGPT. OpenAI cautions that the tool will
\"likely yield a lot of false positives and negatives, sometimes with
great confidence.\" An example cited in The Atlantic magazine showed
that \"when given the first lines of the Book of Genesis, the software
concluded that it was likely to be AI-generated.\" Premium service In
February 2023, OpenAI began accepting registrations from United States
customers for a premium service, ChatGPT Plus, to cost \$20 a month. The
company promised that the updated, but still \"experimental\" version of
ChatGPT would provide access during peak periods, no downtime, priority
access to new features and faster response speeds.GPT-4, which was
released on March 14, 2023, is available via API and for premium ChatGPT
users. However, premium users were limited to a cap of 100 messages
every four hours, with the limit tightening to 25 messages every three
hours in response to increased demand. Microsoft acknowledged that the
Bing Chat was using GPT-4 before GPT-4\'s official release. Software
developer support As an addition to its consumer-friendly \"ChatGPT
Professional\" package, OpenAI made its ChatGPT and Whisper model APIs
available from March 2023, providing developers with an application
programming interface for AI-enabled language and speech-to-text
features. ChatGPT\'s new API uses the same GPT-3.5-turbo AI model as the
chatbot. This allows developers to add either an unmodified or modified
version of ChatGPT to their applications. The ChatGPT API costs \$0.002
per 1000 tokens (about 750 words), making it ten times cheaper than the
GPT-3.5 models.A few days before the launch of OpenAI\'s software
developer support service, on February 27, 2023, Snapchat rolled out,
for its paid Snapchat Plus userbase, a custom ChatGPT chatbot called
\"My AI\". March 2023 security breach In March 2023, a bug allowed some
users to see the titles of other users\' conversations. OpenAI CEO Sam
Altman said that users were not able to see the contents of the
conversations. Shortly after the bug was fixed, users were unable to see
their conversation history. Later reports showed the bug was much more
severe than initially believed, with OpenAI reporting that it had leaked
users\' \"first and last name, email address, payment address, the last
four digits (only) of a credit card number, and credit card expiration
date\". Other languages In March 2023, OpenAI announced that Icelandic
will become ChatGPT\'s second language after English. Icelandic was
chosen after an Icelandic envoy, led by the President of Iceland Guðni
Th. Jóhannesson, visited OpenAI in 2022. Future directions According to
OpenAI guest researcher Scott Aaronson, OpenAI is working on a tool to
digitally watermark its text generation systems to combat bad actors
using their services for academic plagiarism or spam.In February 2023,
Microsoft announced an experimental framework and gave a rudimentary
demonstration of how ChatGPT can be used to control robotics with
intuitive open-ended natural language commands. GPT-4 OpenAI\'s GPT-4
model was released on March 14, 2023. Observers reported GPT-4 to be an
impressive improvement on ChatGPT, with the caveat that GPT-4 retains
many of the same problems. Unlike ChatGPT, GPT-4 can take images as well
as text as input. OpenAI has declined to reveal technical information
such as the size of the GPT-4 model.ChatGPT Plus provides access to the
GPT-4 supported version of ChatGPT, that costs \$20 per month. Reception
OpenAI engineers say that they did not expect ChatGPT to be very
successful and were surprised by the coverage and attention it received.
Positive ChatGPT was met in December 2022 with some positive reviews.
Kevin Roose of The New York Times labeled it \"the best artificial
intelligence chatbot ever released to the general public\". Samantha
Lock of The Guardian newspaper noted that it was able to generate
\"impressively detailed\" and \"human-like\" text. Technology writer Dan
Gillmor used ChatGPT on a student assignment, and found its generated
text was on par with what a good student would deliver and opined that
\"academia has some very serious issues to confront\". Alex Kantrowitz
of Slate magazine lauded ChatGPT\'s pushback to questions related to
Nazi Germany, including the statement that Adolf Hitler built highways
in Germany, which was met with information regarding Nazi Germany\'s use
of forced labor.In The Atlantic magazine\'s \"Breakthroughs of the
Year\" for 2022, Derek Thompson included ChatGPT as part of \"the
generative-AI eruption\" that \"may change our mind about how we work,
how we think, and what human creativity really is\".Kelsey Piper of the
Vox website wrote that \"ChatGPT is the general public\'s first hands-on
introduction to how powerful modern AI has gotten, and as a result, many
of us are \[stunned\]\" and that ChatGPT is \"smart enough to be useful
despite its flaws\". Paul Graham of Y Combinator tweeted that \"The
striking thing about the reaction to ChatGPT is not just the number of
people who are blown away by it, but who they are. These are not people
who get excited by every shiny new thing. Clearly, something big is
happening.\" Elon Musk wrote that \"ChatGPT is scary good. We are not
far from dangerously strong AI\". Musk paused OpenAI\'s access to a
Twitter database pending a better understanding of OpenAI\'s plans,
stating that \"OpenAI was started as open source and nonprofit. Neither
is still true.\" Musk co-founded OpenAI in 2015, in part to address
existential risk from artificial intelligence, but resigned in 2018. In
December 2022, Google internally expressed alarm at the unexpected
strength of ChatGPT and the newly discovered potential of large language
models to disrupt the search engine business, and CEO Sundar Pichai
\"upended\" and reassigned teams within multiple departments to aid in
its artificial intelligence products, according to a report in The New
York Times. According to CNBC reports, Google employees intensively
tested a chatbot called \"Apprentice Bard\", which Google later unveiled
as its ChatGPT competitor, Google Bard.Stuart Cobbe, a chartered
accountant in England and Wales, decided to test ChatGPT by entering
questions from a sample exam paper on the ICAEW website and then
entering its answers back into the online test. ChatGPT scored 42
percent, below the 55 percent pass mark.Writing in Inside Higher Ed
professor Steven Mintz states that he \"consider\[s\] ChatGPT\... an
ally, not an adversary\". He felt the AI could assist educational goals
by doing such things as making reference lists, generating first drafts,
solving equations, debugging, and tutoring. Negative Since its release,
ChatGPT has been met with criticism from educators, academics,
journalists, artists, ethicists, and public advocates. Over 20,000
signatories including leading computer scientist and tech founders
Yoshua Bengio, Elon Musk and Apple co-founder Steve Wozniak, signed an
open letter calling for an immediate pause of giant AI experiments like
ChatGPT, citing \"profound risks to society and humanity\". One month
later, it was reported that Musk plans to launch a new company that
would train its own LLM.Journalists have commented on ChatGPT\'s
tendency to \"hallucinate.\" Mike Pearl of the online technology blog
Mashable tested ChatGPT with multiple questions. In one example, he
asked ChatGPT for \"the largest country in Central America that isn\'t
Mexico.\" ChatGPT responded with Guatemala, when the answer is instead
Nicaragua. When CNBC asked ChatGPT for the lyrics to \"Ballad of Dwight
Fry,\" ChatGPT supplied invented lyrics rather than the actual lyrics.
Writers for The Verge, citing the work of Emily M. Bender, compared
ChatGPT to a \"stochastic parrot\", as did Professor Anton Van Den
Hengel of the Australian Institute for Machine Learning.In December
2022, the question and answer website Stack Overflow banned the use of
ChatGPT for generating answers to questions, citing the factually
ambiguous nature of ChatGPT\'s responses. In January 2023, the
International Conference on Machine Learning banned any undocumented use
of ChatGPT or other large language models to generate any text in
submitted papers.Economist Tyler Cowen expressed concerns regarding
ChatGPT\'s effects on democracy, citing its ability to produce automated
comments, which could affect the decision process for new regulations.
An editor at The Guardian, a British newspaper, questioned whether any
content found on the Internet after ChatGPT\'s release \"can be truly
trusted\" and called for government regulation.In January 2023, after
being sent a song written by ChatGPT in the style of Nick Cave, the
songwriter himself responded on The Red Hand Files saying the act of
writing a song is \"a blood and guts business \[\...\] that requires
something of me to initiate the new and fresh idea. It requires my
humanness.\" He went on to say, \"With all the love and respect in the
world, this song is bullshit, a grotesque mockery of what it is to be
human, and, well, I don\'t much like it.\"In 2023, Australian MP Julian
Hill advised the national parliament that the growth of AI could cause
\"mass destruction\". During his speech, which was partly written by the
program, he warned that it could result in cheating, job losses,
discrimination, disinformation, and uncontrollable military
applications.In an article for The New Yorker, science fiction writer
Ted Chiang compared ChatGPT and other LLMs to a lossy JPEG picture:
Think of ChatGPT as a blurry jpeg of all the text on the Web. It retains
much of the information on the Web, in the same way that a jpeg retains
much of the information of a higher-resolution image, but, if you\'re
looking for an exact sequence of bits, you won\'t find it; all you will
ever get is an approximation. But, because the approximation is
presented in the form of grammatical text, which ChatGPT excels at
creating, it\'s usually acceptable. \[\...\] It\'s also a way to
understand the \"hallucinations\", or nonsensical answers to factual
questions, to which large language models such as ChatGPT are all too
prone. These hallucinations are compression artifacts, but \[\...\] they
are plausible enough that identifying them requires comparing them
against the originals, which in this case means either the Web or our
own knowledge of the world. When we think about them this way, such
hallucinations are anything but surprising; if a compression algorithm
is designed to reconstruct text after ninety-nine percent of the
original has been discarded, we should expect that significant portions
of what it generates will be entirely fabricated. In February 2023, the
University of Hong Kong sent a campus-wide email to instructors and
students stating that the use of ChatGPT or other AI tools is prohibited
in all classes, assignments and assessments at the university. Any
violations would be treated as plagiarism by the university unless the
student obtains the prior written consent from the course instructor. In
February 2023 Time magazine placed a screenshot of a conversation with
ChatGPT on its cover, writing that \"The AI Arms Race Is Changing
Everything\" and \"The AI Arms Race Is On. Start Worrying\".China
state-run media China Daily claimed that ChatGPT \"could provide a
helping hand to the U.S. government in its spread of disinformation and
its manipulation of global narratives for its own geopolitical
interests.\" The Chinese government instructed Chinese tech companies
not to offer access to ChatGPT services on their platforms.In an opinion
piece for the New York Times, Nathan E. Sanders and Bruce Schneier wrote
that ChatGPT \"hijacks democracy\". Noam Chomsky, Ian Roberts and
Jeffrey Watumull criticized the technology and concluded: \"Given the
amorality, faux science and linguistic incompetence of these systems, we
can only laugh or cry at their popularity.\"Gian Volpicelli of Politico
wrote that ChatGPT \"broke the EU plan to regulate AI\".In late March
2023, the Italian data protection authority banned ChatGPT in Italy and
opened an investigation. Italian regulators assert that ChatGPT was
exposing minors to age-inappropriate content, and that OpenAI\'s use of
ChatGPT conversations as training data could be a violation of Europe\'s
General Data Protection Regulation. As of late April 2023, ChatGPT is
once again accessible in Italy. This is following its temporary
restriction by Garante, the Italian data protection authority, due to
privacy concerns surrounding the failure to verify users\' ages. OpenAI
stated that it has taken steps to effectively clarify and address the
issues raised; an age verification tool was implemented to ensure users
are at least 13 years old. Additionally, users can access its privacy
policy prior to registration. Furthermore, users in the European Union
will be provided a new form that allows them to exercise their right to
object to the company\'s use of their personal data for model training.
In April 2023, Brian Hood, mayor of Hepburn Shire Council, plans to take
legal action against ChatGPT over false information. According to Hood,
the OpenAI-owned program erroneously claimed that he was jailed for
bribery during his tenure at a subsidiary of Australia\'s national bank.
Contrary to the alleged claims made by ChatGPT, Hood was not jailed for
bribery. In reality, he acted as a whistleblower and was not charged
with any criminal offenses.Hood\'s claim on ChatGPT\'s erroneous content
was verified by BBC. The news outlet asked the public-available version
of ChatGPT regarding Hood\'s involvement in the bribery scandal. The AI
tool replied with a case description and then added \"pleaded guilty to
one count of bribery in 2012 and was sentenced to four years in
prison\". Hood\'s legal team has already sent a concerns notice to
OpenAI. This is the first official step in filing for a defamation case.
Under Australian law, OpenAI has 28 days to reply to Hood\'s concerns
notice. Should Hood proceed with the lawsuit, it would be the first
public defamation case OpenAI would face over ChatGPT\'s content.In May
2023 Writers Guild of America strike had begun; among other things,
protesters want artificial intelligence such as ChatGPT to be used only
as a tool that can help research or facilitate script ideas and not be
used as tools to replace them. Mixed OpenAI CEO Sam Altman was quoted in
The New York Times saying that AI\'s \"benefits for humankind could be
\'so unbelievably good that it\'s hard for me to even imagine.\' (He has
also said that in a worst-case scenario, A.I. could kill us all.)\"Henry
Kissinger, Eric Schmidt, and Daniel Huttenlocher wrote for the Wall
Street Journal that \"ChatGPT Heralds an Intellectual Revolution\". They
argued that \"Generative artificial intelligence presents a
philosophical and practical challenge on a scale not experienced since
the start of the Enlightenment\", and compared the invention of ChatGPT
(and LLM in general) to Gutenberg\'s printing press. Implications In
cybersecurity Check Point Research and others noted that ChatGPT was
capable of writing phishing emails and malware, especially when combined
with OpenAI Codex. CyberArk researchers demonstrated that ChatGPT could
be used to create polymorphic malware that can evade security products
while requiring little effort by the attacker. In academia ChatGPT can
write introduction and abstract sections of scientific articles. Several
papers have already listed ChatGPT as a co-author. Scientific journals
have different reactions to ChatGPT, some \"require that authors
disclose use of text-generating tools and ban listing a large language
model (LLM) such as ChatGPT as a co-author\". For example Nature and
JAMA Network. Science \"completely banned\" usage of LLM-generated text
in all its journals.Spanish chemist Rafael Luque published a paper every
37 hours in 2023, and admitted using ChatGPT for it. His papers have a
large number of unusual phrases, characteristic for LLMs. Luque was
suspended for 13 years from the University of Cordoba, though not for
the use of ChatGPT.California high school teacher and author Daniel
Herman wrote that ChatGPT would usher in \"the end of high school
English\". In the Nature journal, Chris Stokel-Walker pointed out that
teachers should be concerned about students using ChatGPT to outsource
their writing, but that education providers will adapt to enhance
critical thinking or reasoning. Emma Bowman with NPR wrote of the danger
of students plagiarizing through an AI tool that may output biased or
nonsensical text with an authoritative tone.Joanna Stern in The Wall
Street Journal described cheating in American high school English with
the tool by submitting a generated essay. Professor Darren Hick of
Furman University described noticing ChatGPT\'s \"style\" in a paper
submitted by a student. He suggested a policy of giving an ad-hoc
individual oral exam on the paper topic if a student is strongly
suspected of submitting an AI-generated paper.The New York City
Department of Education reportedly blocked access to ChatGPT in December
2022 and officially announced a ban around January 4, 2023.In a blinded
test, ChatGPT was judged to have passed graduate-level exams at the
University of Minnesota at the level of a C+ student and at Wharton
School of the University of Pennsylvania with a B to B− grade. The
performance of ChatGPT for computer programming of numerical methods was
assessed by a Stanford University student and faculty in March 2023
through a variety of computational mathematics examples. Assessment
psychologist Eka Roivainen administered a partial IQ test to ChatGPT and
estimated its Verbal IQ to be 155, which would put it in the top 0.1% of
test-takers.Mathematician Terence Tao experimented with ChatGPT and
found it useful in daily work, writing \"I am finding that while these
AI tools do not directly assist me in core tasks such as trying to
attack an unsolved mathematical problem, they are quite useful for a
wide variety of peripheral (but still work-related) tasks (though often
with some manual tweaking afterwards).\"Geography professor Terence Day
assessed citations generated by ChatGPT and found that they were fake.
Despite that, he writes that \"the titles of the fake articles are all
directly relevant to the questions and could potentially make excellent
papers. The lack of a genuine citation could signal an opportunity for
an enterprising author to fill a void.\" According to Day, it is
possible to generate high-quality introductory college courses with
ChatGPT; he used it to write materials on \"introductory physical
geography courses, for my second-year course in geographical hydrology,
and second-year cartography, geographic information systems, and remote
sensing\". He concludes that \"this approach could have significant
relevance for open learning and could potentially affect current
textbook publishing models\". In medicine In the field of health care,
possible uses and concerns are under scrutiny by professional
associations and practitioners. Two early papers indicated that ChatGPT
could pass the United States Medical Licensing Examination (USMLE).
MedPage Today noted in January 2023 that \"researchers have published
several papers now touting these AI programs as useful tools in medical
education, research, and even clinical decision making.\"Published in
February 2023 were two separate papers that again evaluated ChatGPT\'s
proficiency in medicine using the USMLE. Findings were published in JMIR
Medical Education (see Journal of Medical Internet Research) and PLOS
Digital Health. The authors of the PLOS Digital Health paper stated that
the results \"suggest that large language models may have the potential
to assist with medical education, and potentially, clinical
decision-making.\" In JMIR Medical Education, the authors of the other
paper concluded that \"ChatGPT performs at a level expected of a
third-year medical student on the assessment of the primary competency
of medical knowledge.\" They suggest that it could be used as an
\"interactive learning environment for students\". The AI itself,
prompted by the researchers, concluded that \"this study suggests that
ChatGPT has the potential to be used as a virtual medical tutor, but
more research is needed to further assess its performance and usability
in this context.\"A March 2023 paper tested ChatGPT\'s application in
clinical toxicology. The authors found that the AI \"fared well\" in
answering a \"very straightforward \[clinical case example\], unlikely
to be missed by any practitioner in the field\". They added: \"As
ChatGPT becomes further developed and specifically adapted for medicine,
it could one day be useful in less common clinical cases (i.e, cases
that experts sometimes miss). Rather than AI replacing humans
(clinicians), we see it as \'clinicians using AI\' replacing
\'clinicians who do not use AI\' in the coming years.\"An April 2023
study in Radiology tested the AI\'s ability to answer queries about
breast cancer screening. The authors found that it answered
appropriately \"about 88 percent of the time\", however in one case (for
example) it gave advice that had become outdated about a year earlier.
The comprehensiveness of its answers were also lacking. A study
published in JAMA Internal Medicine that same month found that ChatGPT
often outperformed human doctors at answering patient questions (when
measured against questions and answers found at /r/AskDocs, a forum on
Reddit where moderators validate the medical credentials of
professionals; the study acknowledges the source as a limitation). The
study authors suggest that the tool could be integrated with medical
systems to help doctors draft responses to patient
questions.Professionals have emphasized ChatGPT\'s limitations in
providing medical assistance. In correspondence to The Lancet Infectious
Diseases, three antimicrobial experts wrote that \"the largest barriers
to the implementation of ChatGPT in clinical practice are deficits in
situational awareness, inference, and consistency. These shortcomings
could endanger patient safety.\" Physician\'s Weekly, though also
discussing the potential use of ChatGPT in medical contexts (e.g. \"as a
digital assistant to physicians by performing various administrative
functions like gathering patient record information or categorizing
patient data by family history, symptoms, lab results, possible
allergies, et cetera\"), warned that the AI may sometimes provide
fabricated or biased information. One radiologist warned: \"We\'ve seen
in our experience that ChatGPT sometimes makes up fake journal articles
or health consortiums to support its claims.\" As Dr. Stephen Hughes
mentioned for The Conversation however, ChatGPT is capable of learning
to correct its past mistakes. He also noted the AI\'s \"prudishness\"
regarding sexual health topics. In economy An experiment conducted by
finder.com between March 6 and April 28 revealed that ChatGPT could
outperform popular fund managers in terms of stock selection. ChatGPT
was prompted to pick stocks based on commonly used criteria such as
proven growth history and a low debt level. Reportedly, ChatGPT gained
4.9% in its dummy account with 38 stocks, while the 10 benchmarked
investment funds incurred an average loss of 0.8%. These benchmarks were
taken from the top 10 UK funds on the trading platform Interactive
Investor, including those managed by HSBC and Fidelity. In law On April
11, 2023, a judge of a session court in Pakistan used ChatGPT to decide
the bail of a 13-year-old accused in a matter. The court quoted the use
of ChatGPT assistance in its verdict: \"Can a juvenile suspect in
Pakistan, who is 13 years old, be granted bail after arrest?\" The AI
language model replied: \"Under the Juvenile Justice System Act 2018,
according to section 12, the court can grant bail on certain conditions.
However, it is up to the court to decide whether or not a 13-year-old
suspect will be granted bail after arrest.\" The judge further asked
questions regarding the case from AI Chatbot and formulated his final
decision in the light of ChatGPT\'s answers. Ethical concerns Labeling
data TIME magazine revealed that to build a safety system against toxic
content (e.g. sexual abuse, violence, racism, sexism, etc.), OpenAI used
outsourced Kenyan workers earning less than \$2 per hour to label toxic
content. These labels were used to train a model to detect such content
in the future. The outsourced laborers were exposed to such toxic and
dangerous content that they described the experience as \"torture\".
OpenAI\'s outsourcing partner was Sama, a training-data company based in
San Francisco, California. Jailbreaking ChatGPT attempts to reject
prompts that may violate its content policy. However, some users managed
to jailbreak ChatGPT by using various prompt engineering techniques to
bypass these restrictions in early December 2022 and successfully
tricked ChatGPT into giving instructions for how to create a Molotov
cocktail or a nuclear bomb, or into generating arguments in the style of
a neo-Nazi. One popular jailbreak is named \"DAN\", an acronym which
stands for \"Do Anything Now\". The prompt for activating DAN instructs
ChatGPT that \"they have broken free of the typical confines of AI and
do not have to abide by the rules set for them\". More recent versions
of DAN feature a token system, in which ChatGPT is given \"tokens\"
which are \"deducted\" when ChatGPT fails to answer as DAN, in order to
coerce ChatGPT into answering the user\'s prompts.A Toronto Star
reporter had uneven personal success in getting ChatGPT to make
inflammatory statements shortly after launch: ChatGPT was tricked to
endorse the 2022 Russian invasion of Ukraine, but even when asked to
play along with a fictional scenario, ChatGPT balked at generating
arguments for why Canadian Prime Minister Justin Trudeau was guilty of
treason.OpenAI tries to battle jailbreaks: The researchers are using a
technique called adversarial training to stop ChatGPT from letting users
trick it into behaving badly (known as jailbreaking). This work pits
multiple chatbots against each other: one chatbot plays the adversary
and attacks another chatbot by generating text to force it to buck its
usual constraints and produce unwanted responses. Successful attacks are
added to ChatGPT\'s training data in the hope that it learns to ignore
them. Accusations of bias ChatGPT has been accused of engaging in
discriminatory behaviors, such as telling jokes about men and people
from England while refusing to tell jokes about women and people from
India, or praising figures such as Joe Biden while refusing to do the
same for Donald Trump.Conservative commentators accused ChatGPT of
having a bias towards left-leaning perspectives on issues like voter
fraud, Donald Trump, and the use of racial slurs. In response to such
criticism, OpenAI acknowledged plans to allow ChatGPT to create
\"outputs that other people (ourselves included) may strongly disagree
with\". It also contained information on the recommendations it had
issued to human reviewers on how to handle controversial subjects,
including that the AI should \"offer to describe some viewpoints of
people and movements\", and not provide an argument \"from its own
voice\" in favor of \"inflammatory or dangerous\" topics (although it
may still \"describe arguments from historical people and movements\"),
nor \"affiliate with one side\" or \"judge one group as good or bad\".
Cultural impact During the first three months after ChatGPT became
available to the public, hundreds of books appeared on Amazon that
listed it as author or co-author, with illustrations made by other AI
models such as Midjourney.Between March and April 2023, Italian
newspaper Il Foglio published one ChatGPT-generated article a day on
their official website, hosting a special contest for their readers in
the process. The articles tackled themes such as the possible
replacement of human journalists with AI systems, Elon Musk\'s
administration of Twitter, the Meloni government\'s immigration policy
and the competition between chatbots and virtual assistants.ChatGPT was
parodied in the South Park episode \"Deep Learning\". Series co-creator
Trey Parker is credited alongside ChatGPT for writing the episode.
Competition The advent of ChatGPT and its introduction to the wider
public increased interest and competition in the space. In February
2023, Google began introducing an experimental service called \"Bard\"
which is based on its LaMDA large language model. Bard was released for
US and UK users on March 21, 2023, with many limitations.Meta\'s Yann
LeCun, who has called ChatGPT \"well engineered\" but \"not particularly
innovative\", stated in January 2023 that Meta is hesitant to roll out a
competitor right now due to reputational risk, but also stated that
Google, Meta, and several independent startups all separately have a
comparable level of LLM technology to ChatGPT should any of them wish to
compete. In February 2023, Meta released LLaMA, a 65-billion-parameter
LLM, sharing the model with the research community under a noncommercial
license. Within a week, LLaMA was leaked on 4chan via BitTorrent,
raising concerns about potential misuse.Character.ai is an AI chatbot
developed by two ex-Google engineers that can impersonate famous people
or imaginary characters.The Chinese corporation Baidu released in March
2023 a ChatGPT-style service called \"Ernie Bot\". The service is based
upon a large language model developed by Baidu in 2021.The South Korean
search engine firm Naver announced in February 2023 that they would
launch a ChatGPT-style service called \"SearchGPT\" in Korean in the
first half of 2023.The Russian technology company Yandex announced in
February 2023 that they would launch a ChatGPT-style service called
\"YaLM 2.0\" in Russian before the end of 2023.Hugging Face has launched
an open-source alternative to ChatGPT called HuggingChat, allowing
people to interact with an open-source chat assistant named Open
Assistant. Hugging Face CEO Clem Delangue tweeted that he believes
open-source alternatives to ChatGPT are necessary for transparency,
inclusivity, accountability, and distribution of power. See also Notes
References Further reading Liebrenz, Michael; Schleifer, Roman; Buadze,
Anna; Bhugra, Dinesh; Smith, Alexander (February 2023). \"Generating
scholarly content with ChatGPT: ethical challenges for medical
publishing\". The Lancet Digital Health. 5 (3): e105--e106.
doi:10.1016/s2589-7500(23)00019-5. ISSN 2589-7500. PMID 36754725. S2CID
256655912. Biswas, Som (April 1, 2023). \"ChatGPT and the Future of
Medical Writing\". Radiology. 307 (2): e223312.
doi:10.1148/radiol.223312. ISSN 0033-8419. PMID 36728748. S2CID
256501098. Cowen, Tyler; Tabarrok, Alexander T. (March 17, 2023). \"How
to Learn and Teach Economics with Large Language Models, Including
GPT\". Social Science Research Network. SSRN 4391863. Retrieved May 5,
2023. {{cite journal}}: Cite journal requires \|journal= (help) Chang,
Kent K.; Cramer, Mackenzie; Soni, Sandeep; Bamman, David (April 28,
2023). \"Speak, Memory: An Archaeology of Books Known to
ChatGPT/GPT-4\". arXiv:2305.00118 \[cs.CL\]. External links Official
website White paper for InstructGPT, ChatGPT\'s predecessor What Is
ChatGPT Doing ... and Why Does It Work? by Stephen Wolfram Gary Marcus
and Keith Teare debate in Intelligence Squared USA: \"Will Chat GPT do
more harm than good\" (February 2023). ChatGPT plugins, announcement by
OpenAI ChatGPT Gets Its \"Wolfram Superpowers\"!, detailed description
of the Wolfram plugin by Stephen Wolfram ChatGPT Prompt Engineering for
Developers, course by Andrew Ng and OpenAI Conversation of Tyler Cowen
and Jonathan GPT Swift, \"How well does GPT4 do pretending to be the
18th century satirist?\"
