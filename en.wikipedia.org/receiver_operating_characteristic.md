A receiver operating characteristic curve, or ROC curve, is a graphical
plot that illustrates the diagnostic ability of a binary classifier
system as its discrimination threshold is varied. The method was
originally developed for operators of military radar receivers starting
in 1941, which led to its name. The ROC curve is created by plotting the
true positive rate (TPR) against the false positive rate (FPR) at
various threshold settings. The true-positive rate is also known as
sensitivity, recall or probability of detection. The false-positive rate
is also known as probability of false alarm and can be calculated as (1
− specificity). The ROC can also be thought of as a plot of the power as
a function of the Type I Error of the decision rule (when the
performance is calculated from just a sample of the population, it can
be thought of as estimators of these quantities). The ROC curve is thus
the sensitivity or recall as a function of fall-out. In general, if the
probability distributions for both detection and false alarm are known,
the ROC curve can be generated by plotting the cumulative distribution
function (area under the probability distribution from − ∞
{\\displaystyle -\\infty } to the discrimination threshold) of the
detection probability in the y-axis versus the cumulative distribution
function of the false-alarm probability on the x-axis. ROC analysis
provides tools to select possibly optimal models and to discard
suboptimal ones independently from (and prior to specifying) the cost
context or the class distribution. ROC analysis is related in a direct
and natural way to cost/benefit analysis of diagnostic decision making.
The ROC curve was first developed by electrical engineers and radar
engineers during World War II for detecting enemy objects in
battlefields and was soon introduced to psychology to account for
perceptual detection of stimuli. ROC analysis since then has been used
in medicine, radiology, biometrics, forecasting of natural hazards,
meteorology, model performance assessment, and other areas for many
decades and is increasingly used in machine learning and data mining
research. The ROC is also known as a relative operating characteristic
curve, because it is a comparison of two operating characteristics (TPR
and FPR) as the criterion changes. Basic concept A classification model
(classifier or diagnosis) is a mapping of instances between certain
classes/groups. Because the classifier or diagnosis result can be an
arbitrary real value (continuous output), the classifier boundary
between classes must be determined by a threshold value (for instance,
to determine whether a person has hypertension based on a blood pressure
measure). Or it can be a discrete class label, indicating one of the
classes. Consider a two-class prediction problem (binary
classification), in which the outcomes are labeled either as positive
(p) or negative (n). There are four possible outcomes from a binary
classifier. If the outcome from a prediction is p and the actual value
is also p, then it is called a true positive (TP); however if the actual
value is n then it is said to be a false positive (FP). Conversely, a
true negative (TN) has occurred when both the prediction outcome and the
actual value are n, and false negative (FN) is when the prediction
outcome is n while the actual value is p. To get an appropriate example
in a real-world problem, consider a diagnostic test that seeks to
determine whether a person has a certain disease. A false positive in
this case occurs when the person tests positive, but does not actually
have the disease. A false negative, on the other hand, occurs when the
person tests negative, suggesting they are healthy, when they actually
do have the disease. Let us define an experiment from P positive
instances and N negative instances for some condition. The four outcomes
can be formulated in a 2×2 contingency table or confusion matrix, as
follows: ROC space The contingency table can derive several evaluation
\"metrics\" (see infobox). To draw a ROC curve, only the true positive
rate (TPR) and false positive rate (FPR) are needed (as functions of
some classifier parameter). The TPR defines how many correct positive
results occur among all positive samples available during the test. FPR,
on the other hand, defines how many incorrect positive results occur
among all negative samples available during the test. A ROC space is
defined by FPR and TPR as x and y axes, respectively, which depicts
relative trade-offs between true positive (benefits) and false positive
(costs). Since TPR is equivalent to sensitivity and FPR is equal to 1 −
specificity, the ROC graph is sometimes called the sensitivity vs (1 −
specificity) plot. Each prediction result or instance of a confusion
matrix represents one point in the ROC space. The best possible
prediction method would yield a point in the upper left corner or
coordinate (0,1) of the ROC space, representing 100% sensitivity (no
false negatives) and 100% specificity (no false positives). The (0,1)
point is also called a perfect classification. A random guess would give
a point along a diagonal line (the so-called line of no-discrimination)
from the bottom left to the top right corners (regardless of the
positive and negative base rates). An intuitive example of random
guessing is a decision by flipping coins. As the size of the sample
increases, a random classifier\'s ROC point tends towards the diagonal
line. In the case of a balanced coin, it will tend to the point (0.5,
0.5). The diagonal divides the ROC space. Points above the diagonal
represent good classification results (better than random); points below
the line represent bad results (worse than random). Note that the output
of a consistently bad predictor could simply be inverted to obtain a
good predictor. Let us look into four prediction results from 100
positive and 100 negative instances: Plots of the four results above in
the ROC space are given in the figure. The result of method A clearly
shows the best predictive power among A, B, and C. The result of B lies
on the random guess line (the diagonal line), and it can be seen in the
table that the accuracy of B is 50%. However, when C is mirrored across
the center point (0.5,0.5), the resulting method C′ is even better than
A. This mirrored method simply reverses the predictions of whatever
method or test produced the C contingency table. Although the original C
method has negative predictive power, simply reversing its decisions
leads to a new predictive method C′ which has positive predictive power.
When the C method predicts p or n, the C′ method would predict n or p,
respectively. In this manner, the C′ test would perform the best. The
closer a result from a contingency table is to the upper left corner,
the better it predicts, but the distance from the random guess line in
either direction is the best indicator of how much predictive power a
method has. If the result is below the line (i.e. the method is worse
than a random guess), all of the method\'s predictions must be reversed
in order to utilize its power, thereby moving the result above the
random guess line. Curves in ROC space In binary classification, the
class prediction for each instance is often made based on a continuous
random variable X {\\displaystyle X} , which is a \"score\" computed for
the instance (e.g. the estimated probability in logistic regression).
Given a threshold parameter T {\\displaystyle T} , the instance is
classified as \"positive\" if X \> T {\\displaystyle X\>T} , and
\"negative\" otherwise. X {\\displaystyle X} follows a probability
density f 1 ( x ) {\\displaystyle f\_{1}(x)} if the instance actually
belongs to class \"positive\", and f 0 ( x ) {\\displaystyle f\_{0}(x)}
if otherwise. Therefore, the true positive rate is given by TPR ( T ) =
∫ T ∞ f 1 ( x ) d x {\\displaystyle {\\mbox{TPR}}(T)=\\int
\_{T}\^{\\infty }f\_{1}(x)\\,dx} and the false positive rate is given by
FPR ( T ) = ∫ T ∞ f 0 ( x ) d x {\\displaystyle {\\mbox{FPR}}(T)=\\int
\_{T}\^{\\infty }f\_{0}(x)\\,dx} . The ROC curve plots parametrically
TPR ( T ) {\\displaystyle {\\mbox{TPR}}(T)} versus FPR ( T )
{\\displaystyle {\\mbox{FPR}}(T)} with T {\\displaystyle T} as the
varying parameter. For example, imagine that the blood protein levels in
diseased people and healthy people are normally distributed with means
of 2 g/dL and 1 g/dL respectively. A medical test might measure the
level of a certain protein in a blood sample and classify any number
above a certain threshold as indicating disease. The experimenter can
adjust the threshold (green vertical line in the figure), which will in
turn change the false positive rate. Increasing the threshold would
result in fewer false positives (and more false negatives),
corresponding to a leftward movement on the curve. The actual shape of
the curve is determined by how much overlap the two distributions have.
Further interpretations Sometimes, the ROC is used to generate a summary
statistic. Common versions are: the intercept of the ROC curve with the
line at 45 degrees orthogonal to the no-discrimination line - the
balance point where Sensitivity = 1 - Specificity the intercept of the
ROC curve with the tangent at 45 degrees parallel to the
no-discrimination line that is closest to the error-free point (0,1) -
also called Youden\'s J statistic and generalized as Informedness the
area between the ROC curve and the no-discrimination line multiplied by
two is called the Gini coefficient. It should not be confused with the
measure of statistical dispersion also called Gini coefficient. the area
between the full ROC curve and the triangular ROC curve including only
(0,0), (1,1) and one selected operating point ( t p r , f p r )
{\\displaystyle (tpr,fpr)} - Consistency the area under the ROC curve,
or \"AUC\" (\"area under curve\"), or A\' (pronounced \"a-prime\"), or
\"c-statistic\" (\"concordance statistic\"). the sensitivity index d′
(pronounced \"d-prime\"), the distance between the mean of the
distribution of activity in the system under noise-alone conditions and
its distribution under signal-alone conditions, divided by their
standard deviation, under the assumption that both these distributions
are normal with the same standard deviation. Under these assumptions,
the shape of the ROC is entirely determined by d′.However, any attempt
to summarize the ROC curve into a single number loses information about
the pattern of tradeoffs of the particular discriminator algorithm.
Probabilistic interpretation When using normalized units, the area under
the curve (often referred to as simply the AUC) is equal to the
probability that a classifier will rank a randomly chosen positive
instance higher than a randomly chosen negative one (assuming
\'positive\' ranks higher than \'negative\'). In other words, when given
one randomly selected positive instance and one randomly selected
negative instance, AUC is the probability that the classifier will be
able to tell which one is which. This can be seen as follows: the area
under the curve is given by (the integral boundaries are reversed as
large threshold T {\\displaystyle T} has a lower value on the x-axis)
TPR ( T ) : T ↦ y ( x ) {\\displaystyle {\\mbox{TPR}}(T):T\\mapsto y(x)}
FPR ( T ) : T ↦ x {\\displaystyle {\\mbox{FPR}}(T):T\\mapsto x} A = ∫ x
= 0 1 TPR ( FPR − 1 ( x ) ) d x = ∫ ∞ − ∞ TPR ( T ) FPR ′ ( T ) d T = ∫
− ∞ ∞ ∫ − ∞ ∞ I ( T ′ ≥ T ) f 1 ( T ′ ) f 0 ( T ) d T ′ d T = P ( X 1 ≥
X 0 ) {\\displaystyle A=\\int
\_{x=0}\^{1}{\\mbox{TPR}}({\\mbox{FPR}}\^{-1}(x))\\,dx=\\int \_{\\infty
}\^{-\\infty }{\\mbox{TPR}}(T){\\mbox{FPR}}\'(T)\\,dT=\\int \_{-\\infty
}\^{\\infty }\\int \_{-\\infty }\^{\\infty }I(T\'\\geq
T)f\_{1}(T\')f\_{0}(T)\\,dT\'\\,dT=P(X\_{1}\\geq X\_{0})} where X 1
{\\displaystyle X\_{1}} is the score for a positive instance and X 0
{\\displaystyle X\_{0}} is the score for a negative instance, and f 0
{\\displaystyle f\_{0}} and f 1 {\\displaystyle f\_{1}} are probability
densities as defined in previous section. Area under the curve It can be
shown that the AUC is closely related to the Mann--Whitney U, which
tests whether positives are ranked higher than negatives. It is also
equivalent to the Wilcoxon test of ranks. For a predictor f {\\textstyle
f} , an unbiased estimator of its AUC can be expressed by the following
Wilcoxon-Mann-Whitney statistic: A U C ( f ) = ∑ t 0 ∈ D 0 ∑ t 1 ∈ D 1 1
\[ f ( t 0 ) \< f ( t 1 ) \] \| D 0 \| ⋅ \| D 1 \| , {\\displaystyle
AUC(f)={\\frac {\\sum \_{t\_{0}\\in {\\mathcal {D}}\^{0}}\\sum
\_{t\_{1}\\in {\\mathcal {D}}\^{1}}{\\textbf {1}}\[f(t\_{0})
