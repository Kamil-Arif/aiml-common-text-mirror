Data collection or data gathering is the process of gathering and
measuring information on targeted variables in an established system,
which then enables one to answer relevant questions and evaluate
outcomes. Data collection is a research component in all study fields,
including physical and social sciences, humanities, and business. While
methods vary by discipline, the emphasis on ensuring accurate and honest
collection remains the same. The goal for all data collection is to
capture quality evidence that allows analysis to lead to the formulation
of convincing and credible answers to the questions that have been
posed. Data collection and validation consists of four steps when it
involves taking a census and seven steps when it involves
sampling.Regardless of the field of or preference for defining data
(quantitative or qualitative), accurate data collection is essential to
maintain research integrity. The selection of appropriate data
collection instruments (existing, modified, or newly developed) and
delineated instructions for their correct use reduce the likelihood of
errors. A formal data collection process is necessary as it ensures that
the data gathered are both defined and accurate. This way, subsequent
decisions based on arguments embodied in the findings are made using
valid data. The process provides both a baseline from which to measure
and in certain cases an indication of what to improve. Data management
platform Data management platform (DMP) is a centralized storage and
analytical system for data. Mainly used by marketers, DMPs exist to
compile and transform large amounts of data into discernible
information. Marketers may want to receive and utilize first, second and
third-party data. DMPs enable this, because they are the aggregate
system of DSPs (demand side platform) and SSPs (supply side platform).
When it comes to advertising, DMPs are integral for optimizing and
guiding marketers in future campaigns. This system and their
effectiveness is proof that categorized, analyzed, and compiled data is
far more useful than raw data. Data integrity issues The main reason for
maintaining data integrity is to support the observation of errors in
the data collection process. Those errors may be made intentionally
(deliberate falsification) or non-intentionally (random or systematic
errors).There are two approaches that may protect data integrity and
secure scientific validity of study results invented by Craddick,
Crawford, Rhodes, Redican, Rukenbrod and Laws in 2003: Quality assurance
-- all actions carried out before data collection Quality control -- all
actions carried out during and after data collection Quality assurance
Its main focus is prevention which is primarily a cost-effective
activity to protect the integrity of data collection. Standardization of
protocol best demonstrates this cost-effective activity, which is
developed in a comprehensive and detailed procedures manual for data
collection. The risk of failing to identify problems and errors in the
research process is evidently caused by poorly written guidelines.
Listed are several examples of such failures: Uncertainty of timing,
methods and identification of the responsible person Partial listing of
items needed to be collected Vague description of data collection
instruments instead of rigorous step-by-step instructions on
administering tests Failure to recognize exact content and strategies
for training and retraining staff members responsible for data
collection Unclear instructions for using, making adjustments to, and
calibrating data collection equipment No predetermined mechanism to
document changes in procedures that occur during the investigation User
privacy issues According to Faye Wang, there are serious concerns about
the integrity of individual user data collected by cloud computing,
because this data is transferred acrose countries that have different
standards of protection for individual user data. Information processing
has advanced to the level where user data can now be used predict what
an individual is say before they even speak. Quality control Since
quality control actions occur during or after the data collection all
the details are carefully documented. There is a necessity for a clearly
defined communication structure as a precondition for establishing
monitoring systems. Uncertainty about the flow of information is not
recommended as a poorly organized communication structure leads to lax
monitoring and can also limit the opportunities for detecting errors.
Quality control is also responsible for the identification of actions
necessary for correcting faulty data collection practices and also
minimizing such future occurrences. A team is more likely to not realize
the necessity to perform these actions if their procedures are written
vaguely and are not based on feedback or education. Data collection
problems that necessitate prompt action: Systematic errors Violation of
protocol Fraud or scientific misconduct Errors in individual data items
Individual staff or site performance problems Shadow effect See also
References External links All about data collection -- TechTarget.com
